{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "distractor_gen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6J8EiolcK1YU",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install gensim\n",
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NYASAboYK6Yz",
        "outputId": "82992754-0594-4af3-8dc7-d1cd80a3e5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wm8eA0PlK1Ye",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tmHpo7VuK1Yi",
        "outputId": "875676ae-8714-40d6-af6b-71fe02d122ae",
        "colab": {}
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in ./anaconda3/lib/python3.7/site-packages (3.4)\r\n",
            "Requirement already satisfied: six in ./anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\r\n",
            "Requirement already satisfied: singledispatch in ./anaconda3/lib/python3.7/site-packages (from nltk) (3.4.0.3)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FVVGTjIXK1Yn",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english')) \n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gT1bja9LK1Yt",
        "outputId": "b35ab37a-2668-405b-aecd-ca395aef99eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('Train.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>distractor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Meals can be served</td>\n",
              "      <td>in rooms at 9:00 p. m.</td>\n",
              "      <td>'outside the room at 3:00 p. m.', 'in the dini...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It can be inferred from the passage that</td>\n",
              "      <td>The local government can deal with the problem...</td>\n",
              "      <td>'If some tragedies occur again ', ' relevant d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The author called Tommy 's parents in order to</td>\n",
              "      <td>help them realize their influence on Tommy</td>\n",
              "      <td>'blame Tommy for his failing grades', 'blame T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It can be inferred from the passage that</td>\n",
              "      <td>the writer is not very willing to use idioms</td>\n",
              "      <td>'idioms are the most important part in a langu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can we deal with snake wounds according to...</td>\n",
              "      <td>Stay calm and do n't move .</td>\n",
              "      <td>'Cut the wound and suck the poison out .'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0                                Meals can be served   \n",
              "1           It can be inferred from the passage that   \n",
              "2     The author called Tommy 's parents in order to   \n",
              "3           It can be inferred from the passage that   \n",
              "4  How can we deal with snake wounds according to...   \n",
              "\n",
              "                                         answer_text  \\\n",
              "0                             in rooms at 9:00 p. m.   \n",
              "1  The local government can deal with the problem...   \n",
              "2         help them realize their influence on Tommy   \n",
              "3       the writer is not very willing to use idioms   \n",
              "4                        Stay calm and do n't move .   \n",
              "\n",
              "                                          distractor  \n",
              "0  'outside the room at 3:00 p. m.', 'in the dini...  \n",
              "1  'If some tragedies occur again ', ' relevant d...  \n",
              "2  'blame Tommy for his failing grades', 'blame T...  \n",
              "3  'idioms are the most important part in a langu...  \n",
              "4          'Cut the wound and suck the poison out .'  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_lmJheuDr8EW",
        "outputId": "43dcb6d5-39b2-4d77-8154-3da8ca5ba3e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = list(df['distractor'])\n",
        "a[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'outside the room at 3:00 p. m.', 'in the dining - room at 6:00 p. m.', 'in the dining - room from 7:30 a. m. to 9:15 p. m.'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QO-NsrDWK1Yz",
        "outputId": "4bfac0a6-b797-453a-b1b3-1853cba6f816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dftp = pd.read_csv('Test.csv')\n",
        "dftp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What 'S the main idea of the text ?</td>\n",
              "      <td>The lack of career -- based courses in US high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the summer high season , Finland does nt se...</td>\n",
              "      <td>the sun is out at night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If you want to apply for Chinese Business Inte...</td>\n",
              "      <td>have to get confirmed at least twice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That afternoon , the boy 's clothes were dry b...</td>\n",
              "      <td>nobody made room for him in the water .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which of the following statements is NOT true ?</td>\n",
              "      <td>There are twelve countries in the World Wildli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0                What 'S the main idea of the text ?   \n",
              "1  In the summer high season , Finland does nt se...   \n",
              "2  If you want to apply for Chinese Business Inte...   \n",
              "3  That afternoon , the boy 's clothes were dry b...   \n",
              "4    Which of the following statements is NOT true ?   \n",
              "\n",
              "                                         answer_text  \n",
              "0  The lack of career -- based courses in US high...  \n",
              "1                            the sun is out at night  \n",
              "2               have to get confirmed at least twice  \n",
              "3            nobody made room for him in the water .  \n",
              "4  There are twelve countries in the World Wildli...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jcCP83_t8quR",
        "colab": {}
      },
      "source": [
        "questp = list(dftp['question'])\n",
        "anstp = list(dftp['answer_text'])\n",
        "test_tp = questp + anstp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sEAZnpVtK1Y3",
        "colab": {}
      },
      "source": [
        "questp = list(df['question'])\n",
        "anstp = list(df['answer_text'])\n",
        "test_tp = questp + anstp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wk8e6W_PK1Y8",
        "colab": {}
      },
      "source": [
        "ques = list(df['question'])\n",
        "ans = list(df['answer_text'])\n",
        "dist = list(df['distractor'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ka4mzqlhK1ZB",
        "outputId": "7c7439bb-1c31-4a7a-c3a5-03aa9125a450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dist = [i.split(',') for i in tqdm(dist)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 31499/31499 [00:00<00:00, 1085599.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cPHkJMmRK1ZH",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    \"\"\"\n",
        "    Function to clean the given text\n",
        "    :param text: Sentence string\n",
        "    :return: Cleaned sentence string\n",
        "    \"\"\"\n",
        "    for punct in \"/-'\":\n",
        "        text = text.replace(punct, ' ')\n",
        "    for punct in '&':\n",
        "        text = text.replace(punct, f' {punct} ')\n",
        "    for punct in '.!?,#$%\\()*+-/:\"\"'';=@\"\"[\\\\]^_`{|}~':\n",
        "        text = text.replace(punct, '')\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[?|!|\\'|\"|#]',r' ',text)\n",
        "    text = re.sub(r'[.|,|)|(|\\|/]',r' ',text)        #Removing Punctuations\n",
        "    text = re.sub(r\"what’s\", \"what is \", text)\n",
        "    text = re.sub(r\"\\’s\", \" \", text)\n",
        "    text = re.sub(r\"\\’ve\", \" have \", text)\n",
        "    text = re.sub(r\"hasn’t\", \"has not \", text)\n",
        "    text = re.sub(r\"can’t\", \"cannot \", text)\n",
        "    text = re.sub(r\"n’t\", \" not \", text)\n",
        "    text = re.sub(r\"i’m\", \"i am \", text)\n",
        "    text = re.sub(r\"\\’re\", \" are \", text)\n",
        "    text = re.sub(r\"\\’d\", \" would \", text)\n",
        "    text = re.sub(r\"\\’ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\’scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\d+\\d+', 'NUM', text)\n",
        "    text = text.replace(\"‘\",\"\")\n",
        "    text = text.replace(\"”\", \"\")\n",
        "    text = text.replace(\"“\", \"\")\n",
        "    text = text.replace(\"’\",'')\n",
        "    text = text.replace(\"‘\",\"\")\n",
        "    text = text.replace('''\"\"''','')\n",
        "    text = text.replace('''\"''','')\n",
        "    text = re.sub(r' s ', ' ', text)\n",
        "    return ' '.join(text.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k9BUvGSFK1ZM",
        "outputId": "f0e8cca8-aa8a-411c-fcad-a93e4487e8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.7/site-packages (4.31.1)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v6bZjdtnK1ZQ",
        "outputId": "a67bac20-05cf-4ea1-d89c-5644d8dc1b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def clean(text):\n",
        "    words = word_tokenize(text)\n",
        "    clean_words = [re.sub(r'[^A-Za-z]', '', word) for word in words]\n",
        "    cleaned = ' '.join(clean_words)\n",
        "    text = cleaned.lower()\n",
        "    return text\n",
        "ques = [clean_text(i) for i in tqdm(ques)]\n",
        "ans = [clean_text(i) for i in tqdm(ans)]\n",
        "dist = [[clean_text(j) for j in i] for i in tqdm(dist)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 31499/31499 [00:00<00:00, 54334.22it/s]\n",
            "100%|██████████| 31499/31499 [00:00<00:00, 55511.97it/s]\n",
            "100%|██████████| 31499/31499 [00:01<00:00, 24481.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hvTKyQF1K1ZV",
        "outputId": "821fd55e-a5ca-4c0b-94ad-0cf6405b2e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dist[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['outside the room at NUM p m',\n",
              " 'in the dining room at NUM p m',\n",
              " 'in the dining room from NUM a m to NUM p m']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ew1oio9yK1ZZ",
        "outputId": "4ffd4525-2c8c-4d6c-d9a2-45befaf752a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "comb = []\n",
        "for i, j in tqdm(zip(ques, ans)):\n",
        "    comb.append(i+' ' +j)\n",
        "comb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31499it [00:00, 1818182.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'meals can be served in rooms at NUM p m'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GrSSaahJK1Zg",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "glove = pickle.load(open('glove.42B.300d.pkl','rb')) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nJqTH7JxK1Zq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6vNpHhewK1Zz",
        "outputId": "3b60b888-238f-4923-896b-ec73349c0e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "all_data = []\n",
        "for i in comb:\n",
        "    all_data.append(i)\n",
        "for i in dist:\n",
        "    for j in i:\n",
        "        all_data.append(j)\n",
        "all_data = test_tp + all_data\n",
        "\n",
        "all_data.append('sss')\n",
        "all_data.append('eee')\n",
        "print(len(all_data))\n",
        "all_data[165294]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "165295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eee'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "peZPSU27K1Z6",
        "outputId": "58d3ee61-594d-42c0-f9cc-825191899f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "tk = Tokenizer()\n",
        "tk.fit_on_texts(pd.Series(all_data))\n",
        "def pad_seq(comb, max_len):\n",
        "    X_tokenized= tk.texts_to_sequences(pd.Series(comb).fillna('UNK'))\n",
        "    X_comb = pad_sequences(X_tokenized, maxlen = max_len, padding = 'post', truncating= 'post')\n",
        "    return X_comb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CeuuXebRK1aD",
        "outputId": "b5cb0947-4b95-406e-9352-8ba76a828e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tk.word_index['sss']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24505"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DHamwo4HK1aI",
        "colab": {}
      },
      "source": [
        "a = [-1 for i in range(300)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xXkaOsiCK1aS",
        "colab": {}
      },
      "source": [
        "glove['sss'] = np.ones((1, 300))[0]\n",
        "glove['eee'] = np.array(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y1bESzpgK1ai",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('tk_new.pkl', 'wb') as f:\n",
        "    pickle.dump(tk, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zNF5Oke0K1aq",
        "outputId": "7d5ab177-fe91-4ab7-b2ee-bb70e3ea929a",
        "colab": {}
      },
      "source": [
        "dist_start = []\n",
        "for i in dist:\n",
        "    m = []\n",
        "    for j in i:\n",
        "        m.append('sss ' + j)\n",
        "    dist_start.append(m)\n",
        "dist_start[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sss outside the room at NUM p m',\n",
              " 'sss in the dining room at NUM p m',\n",
              " 'sss in the dining room from NUM a m to NUM p m']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kw5cXrvcK1ax",
        "outputId": "aa7dc8f4-2c14-40b9-d5d5-ace7844650d9",
        "colab": {}
      },
      "source": [
        "dist_end = []\n",
        "for i in dist:\n",
        "    m = []\n",
        "    for j in i:\n",
        "        m.append(j + ' eee')\n",
        "    dist_end.append(m)\n",
        "dist_end[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['outside the room at NUM p m eee',\n",
              " 'in the dining room at NUM p m eee',\n",
              " 'in the dining room from NUM a m to NUM p m eee']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "72DAVWoJK1a4",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_V66oC7IK1a-",
        "colab": {}
      },
      "source": [
        "qa = pad_seq(comb, 20)\n",
        "dist_seq_start = [[pad_seq(j, 20) for j in i] for i in dist_start]\n",
        "dist_seq_end = [[pad_seq(j, 20) for j in i] for i in dist_end]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S6dShThaK1bF",
        "outputId": "4b63a22f-c17c-4f40-880a-929f42e08c27",
        "colab": {}
      },
      "source": [
        "print(len(qa))\n",
        "print(len(dist_seq_start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31499\n",
            "31499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-_OVgLFpK1bK",
        "outputId": "70860725-e102-4950-d5f3-e7cdd30810c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "EMBEDDING_DIM = 300\n",
        "word_index = tk.word_index\n",
        "nb_words = len(word_index) + 1\n",
        "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if word in glove: \n",
        "        embedding_matrix[i] = glove[word]\n",
        "    elif word.lower() in glove:\n",
        "        embedding_matrix[i] = glove[word.lower()]\n",
        "\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
        "print(nb_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: 1653\n",
            "24507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1TRMdIE3K1bP",
        "colab": {}
      },
      "source": [
        "x = [i for i in qa]\n",
        "d1_start = [i[0] for i in dist_seq_start]\n",
        "d2_start = [i[1] if len(i)>=2 else np.zeros((1, 20)) for i in dist_seq_start]\n",
        "d3_start = [i[2] if len(i)>=3 else np.zeros((1, 20)) for i in dist_seq_start]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z6NS8eLkK1bW",
        "colab": {}
      },
      "source": [
        "d1_end = [i[0] for i in dist_seq_end]\n",
        "d2_end = [i[1] if len(i)>=2 else np.zeros((1, 20)) for i in dist_seq_end]\n",
        "d3_end = [i[2] if len(i)>=3 else np.zeros((1, 20)) for i in dist_seq_end]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XpeH8k9fK1bf",
        "outputId": "8d2125c2-2ca3-4a6f-a58d-98b2acd26a7a",
        "colab": {}
      },
      "source": [
        "print(d3_start[10])\n",
        "print(d3_end[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[   90    17   119   270     2  1680  4486 24506     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WlYlCdvCK1bn",
        "outputId": "25471117-415c-41cf-85ca-dfca8768526e",
        "colab": {}
      },
      "source": [
        "print(len(dist))\n",
        "print(len(x))\n",
        "print(len(d1_start))\n",
        "print(len(d2_end))\n",
        "print(len(d3_start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31499\n",
            "31499\n",
            "31499\n",
            "31499\n",
            "31499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eu004iBPK1bv",
        "outputId": "0edfaae7-3a55-4590-edeb-773cc1aa5802",
        "colab": {}
      },
      "source": [
        "x = np.array(x)\n",
        "d1_start = np.array(d1_start)\n",
        "d2_start = np.array(d1_start)\n",
        "d3_start = np.array(d1_start)\n",
        "d3_start.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31499, 1, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IMALisg6K1b3",
        "outputId": "0ff123b7-11d9-4850-84ca-dbe39d1fa941",
        "colab": {}
      },
      "source": [
        "d1_end = np.array(d1_end)\n",
        "d2_end = np.array(d1_end)\n",
        "d3_end = np.array(d1_end)\n",
        "d3_end.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31499, 1, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V0kDCKkHK1cD",
        "outputId": "5af57851-f7ba-4d6f-d1d2-0168a77fe4dc",
        "colab": {}
      },
      "source": [
        "trainx = np.zeros((31499, 20, 300))\n",
        "for i in range(31499):\n",
        "    trainx[i] = embedding_matrix[[x[i]]]\n",
        "\n",
        "traind1s = np.zeros((31499, 20, 300))\n",
        "for i in range(31499):\n",
        "    traind1s[i] = embedding_matrix[[d1_start[i]]]\n",
        "\n",
        "traind2s = np.zeros((31499, 20, 300))\n",
        "for i in range(31499):\n",
        "    try:\n",
        "        traind2s[i] = embedding_matrix[[d2_start[i]]]\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "traind3s = np.zeros((31499, 20, 300))\n",
        "for i in range(31499):\n",
        "    try:\n",
        "        traind3s[i] = embedding_matrix[[d3_start[i]]]\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  import sys\n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  if sys.path[0] == '':\n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pvPF_2JwK1cJ",
        "outputId": "582fb314-7fe0-4fb8-bf24-58351f2a1a5a",
        "colab": {}
      },
      "source": [
        "nb_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sOPC7WmJK1cP",
        "colab": {}
      },
      "source": [
        "inp = 0\n",
        "model = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pV1tG373K1cV",
        "outputId": "360dbd51-80f8-4197-dbc5-31bd9ee0b224",
        "colab": {}
      },
      "source": [
        "import keras.utils as ku\n",
        "traind1e = ku.to_categorical(d1_end[10000:20000], num_classes=24507)\n",
        "traind2e = ku.to_categorical(d2_end[10000:20000], num_classes=24507)\n",
        "traind3e = ku.to_categorical(d3_end[10000:20000], num_classes=24507)\n",
        "traind1e = traind1e.reshape(10000, 20, 24507)\n",
        "traind2e = traind2e.reshape(10000, 20, 24507)\n",
        "traind3e = traind3e.reshape(10000, 20, 24507)\n",
        "traind1e.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 20, 24507)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-GRmBItK1cd",
        "outputId": "9495482a-6fb9-48bf-9f02-48f6573964d3",
        "colab": {}
      },
      "source": [
        "inp = []\n",
        "for i, j, k, l in zip(trainx[10000:20000], traind1s[10000:20000], traind2s[10000:20000], traind3s[10000:20000]):\n",
        "    inp.append([i, j, k, l])\n",
        "inp = np.array(inp).reshape(10000, 4, 20, 300)\n",
        "inp.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 4, 20, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z2G8BjeeK1ch",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import LSTM, Dense, Bidirectional, Input, Dropout, Flatten, Embedding, BatchNormalization, Concatenate, concatenate, Add, Lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7PtiCIiSK1cp",
        "outputId": "e8acafb6-8b00-4257-ec8f-e69ab1eea592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nb_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24507"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kk_6p3xSK1cv",
        "outputId": "ed43a6f3-ac42-4431-8cca-b63b95c17dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "def model():\n",
        "    #inpQA = inp[0]\n",
        "    inpQA = Input(shape=(4, 20, 300))\n",
        "    encoder = LSTM(300, return_state=True)\n",
        "    x1 = Lambda(lambda x:x[:, 0, :])(inpQA)\n",
        "    print(x1.shape)\n",
        "    encoder_outputs, state_h, state_c = encoder(x1)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    decoder_lstm1 = LSTM(300, return_sequences=True, return_state = True)\n",
        "    x2 = Lambda(lambda x:x[:, 1, :])(inpQA)\n",
        "    decoder_outputs1, _, _  = decoder_lstm1(x2,\n",
        "                                      initial_state=encoder_states)\n",
        "    decoder_lstm2 = LSTM(300, return_sequences=True, return_state = True)\n",
        "    x3 = Lambda(lambda x:x[:, 2, :])(inpQA)\n",
        "\n",
        "    decoder_outputs2,  _, _ = decoder_lstm2(x3,\n",
        "                                        initial_state=encoder_states)\n",
        "    decoder_lstm3 = LSTM(300, return_sequences=True, return_state = True)\n",
        "    x4 = Lambda(lambda x:x[:, 3, :])(inpQA)\n",
        "    decoder_outputs3, _, _  = decoder_lstm3(x4,\n",
        "                                        initial_state=encoder_states)\n",
        "\n",
        "    o1 = Dense(24507, activation = 'softmax')(decoder_outputs1)\n",
        "    o2 = Dense(24507, activation = 'softmax')(decoder_outputs2)\n",
        "    o3 = Dense(24507, activation = 'softmax')(decoder_outputs3)\n",
        "                                        \n",
        "    cat_conv = [o1, o2, o3]\n",
        "    \n",
        "\n",
        "    model = Model(inputs=inpQA, outputs = cat_conv)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "model = model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 20, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kbld1NlRK1cy",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath=\"/content/drive/My Drive/ML/Valuelabs/temp.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IgGoFWkoK1c3",
        "outputId": "b1f10793-6e5f-429b-8409-6814308c6df6",
        "colab": {}
      },
      "source": [
        "model.fit(inp, [traind1e, traind2e, traind3e], batch_size=64, epochs=15, verbose=1, callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "10000/10000 [==============================] - 267s 27ms/step - loss: 6.2034 - dense_4_loss: 2.0679 - dense_5_loss: 2.0665 - dense_6_loss: 2.0657 - dense_4_accuracy: 0.6976 - dense_5_accuracy: 0.6978 - dense_6_accuracy: 0.6983\n",
            "Epoch 2/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 258s 26ms/step - loss: 5.4855 - dense_4_loss: 1.8261 - dense_5_loss: 1.8276 - dense_6_loss: 1.8275 - dense_4_accuracy: 0.7087 - dense_5_accuracy: 0.7077 - dense_6_accuracy: 0.7084\n",
            "Epoch 3/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 4.9777 - dense_4_loss: 1.6558 - dense_5_loss: 1.6615 - dense_6_loss: 1.6619 - dense_4_accuracy: 0.7167 - dense_5_accuracy: 0.7162 - dense_6_accuracy: 0.7164\n",
            "Epoch 4/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 4.5051 - dense_4_loss: 1.4972 - dense_5_loss: 1.5050 - dense_6_loss: 1.5049 - dense_4_accuracy: 0.7259 - dense_5_accuracy: 0.7253 - dense_6_accuracy: 0.7255\n",
            "Epoch 5/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 4.0545 - dense_4_loss: 1.3444 - dense_5_loss: 1.3538 - dense_6_loss: 1.3547 - dense_4_accuracy: 0.7383 - dense_5_accuracy: 0.7372 - dense_6_accuracy: 0.7366\n",
            "Epoch 6/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 3.6294 - dense_4_loss: 1.2021 - dense_5_loss: 1.2124 - dense_6_loss: 1.2129 - dense_4_accuracy: 0.7549 - dense_5_accuracy: 0.7533 - dense_6_accuracy: 0.7531\n",
            "Epoch 7/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 3.2371 - dense_4_loss: 1.0716 - dense_5_loss: 1.0814 - dense_6_loss: 1.0835 - dense_4_accuracy: 0.7767 - dense_5_accuracy: 0.7753 - dense_6_accuracy: 0.7741\n",
            "Epoch 8/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 2.8868 - dense_4_loss: 0.9552 - dense_5_loss: 0.9656 - dense_6_loss: 0.9678 - dense_4_accuracy: 0.7993 - dense_5_accuracy: 0.7979 - dense_6_accuracy: 0.7961\n",
            "Epoch 9/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 2.5839 - dense_4_loss: 0.8538 - dense_5_loss: 0.8642 - dense_6_loss: 0.8671 - dense_4_accuracy: 0.8209 - dense_5_accuracy: 0.8193 - dense_6_accuracy: 0.8169\n",
            "Epoch 10/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 2.3135 - dense_4_loss: 0.7632 - dense_5_loss: 0.7741 - dense_6_loss: 0.7767 - dense_4_accuracy: 0.8398 - dense_5_accuracy: 0.8379 - dense_6_accuracy: 0.8361\n",
            "Epoch 11/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 2.0766 - dense_4_loss: 0.6852 - dense_5_loss: 0.6945 - dense_6_loss: 0.6979 - dense_4_accuracy: 0.8572 - dense_5_accuracy: 0.8553 - dense_6_accuracy: 0.8540\n",
            "Epoch 12/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 1.8650 - dense_4_loss: 0.6127 - dense_5_loss: 0.6235 - dense_6_loss: 0.6270 - dense_4_accuracy: 0.8735 - dense_5_accuracy: 0.8715 - dense_6_accuracy: 0.8710\n",
            "Epoch 13/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 1.6720 - dense_4_loss: 0.5498 - dense_5_loss: 0.5602 - dense_6_loss: 0.5632 - dense_4_accuracy: 0.8888 - dense_5_accuracy: 0.8870 - dense_6_accuracy: 0.8856\n",
            "Epoch 14/15\n",
            "10000/10000 [==============================] - 258s 26ms/step - loss: 1.5010 - dense_4_loss: 0.4926 - dense_5_loss: 0.5024 - dense_6_loss: 0.5064 - dense_4_accuracy: 0.9027 - dense_5_accuracy: 0.9002 - dense_6_accuracy: 0.8995\n",
            "Epoch 15/15\n",
            "10000/10000 [==============================] - 259s 26ms/step - loss: 1.3448 - dense_4_loss: 0.4406 - dense_5_loss: 0.4511 - dense_6_loss: 0.4539 - dense_4_accuracy: 0.9163 - dense_5_accuracy: 0.9126 - dense_6_accuracy: 0.9125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fca9640cfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rz0SVrExK1c8",
        "colab": {}
      },
      "source": [
        "model.save('VL2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8ZC671ojK1dA",
        "colab": {}
      },
      "source": [
        "model.load_weights('VL2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6eJ6c8SVtJWu",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RvH-LhOYK1dI",
        "colab": {}
      },
      "source": [
        "def get_seq(sentence, count):\n",
        "    seqq = tk.texts_to_sequences(pd.Series(sentence).fillna('UNK'))\n",
        "    seq_vec = pad_sequences(seqq, maxlen = 20, padding = 'post', truncating= 'post')\n",
        "    emb_vec_qa = embedding_matrix[[seq_vec]]\n",
        "    emb_vec_qa = emb_vec_qa.reshape(20, 300)\n",
        "    d1 = [0 for i in range(20)]\n",
        "    d1 = np.array(d1)\n",
        "    d1[0] = tk.word_index['sss']\n",
        "    d1 = embedding_matrix[[d1]]\n",
        "    d1 = d1.reshape(20, 300)\n",
        "    d2 = [0 for i in range(20)]\n",
        "    d2 = np.array(d2)\n",
        "    d2[0] = tk.word_index['sss']\n",
        "    d2 = embedding_matrix[[d2]]\n",
        "    d2 = d2.reshape(20, 300)\n",
        "    d3 = [0 for i in range(20)]\n",
        "    d3 = np.array(d3)\n",
        "    d3[0] = tk.word_index['sss']\n",
        "    d3 = embedding_matrix[[d3]]\n",
        "    d3 = d3.reshape(20, 300)\n",
        "    inn = []\n",
        "    inn.append([emb_vec_qa, d1, d2, d3])\n",
        "    inn = np.array(inn)\n",
        "    inn = inn.reshape(1, 4, 20, 300)\n",
        "    flag = True\n",
        "    predict1 = []\n",
        "    predict2 = []\n",
        "    predict3 = []\n",
        "    c = 0\n",
        "    while flag:\n",
        "        d1p = np.argmax(model.predict(inn)[0][0][0])\n",
        "        mydict = tk.word_index\n",
        "        if d1p==0:\n",
        "            pred1 = ''\n",
        "            break\n",
        "        word = list(mydict.keys())[list(mydict.values()).index(d1p)]\n",
        "\n",
        "        d1 = [0 for i in range(20)]\n",
        "        d1 = np.array(d1)\n",
        "        d1[0] = tk.word_index[word]\n",
        "        d1 = embedding_matrix[[d1]]\n",
        "        d1 = d1.reshape(20, 300)\n",
        "        inn = []\n",
        "        inn.append([emb_vec_qa, d1, d2, d3])\n",
        "        inn = np.array(inn)\n",
        "        inn = inn.reshape(1, 4, 20, 300)\n",
        "        out = []\n",
        "        c+=1\n",
        "        if word == 'eee' or c > count:\n",
        "            flag = False\n",
        "            pred1 = ' '.join(predict1)\n",
        "        predict1.append(word)\n",
        "\n",
        "\n",
        "\n",
        "#2nd one\n",
        "    c = 0\n",
        "    flag = True\n",
        "    while flag:\n",
        "        d2p = np.argmax(model.predict(inn)[1][0][0])\n",
        "        mydict = tk.word_index\n",
        "        if d2p==0:\n",
        "            pred2 =  ''\n",
        "            break\n",
        "        word = list(mydict.keys())[list(mydict.values()).index(d2p)]\n",
        "\n",
        "        d2 = [0 for i in range(20)]\n",
        "        d2 = np.array(d2)\n",
        "        d2[0] = tk.word_index[word]\n",
        "        d2 = embedding_matrix[[d2]]\n",
        "        d2 = d2.reshape(20, 300)\n",
        "        inn = []\n",
        "        inn.append([emb_vec_qa, d1, d2, d3])\n",
        "        inn = np.array(inn)\n",
        "        inn = inn.reshape(1, 4, 20, 300)\n",
        "        out = []\n",
        "        c+=1\n",
        "        if word == 'eee' or c > count:\n",
        "            flag = False\n",
        "            pred2 =' '.join(predict2)          \n",
        "        predict2.append(word)\n",
        "\n",
        "#third=================\n",
        "    c = 0\n",
        "    flag = True\n",
        "    while flag:\n",
        "        d3p = np.argmax(model.predict(inn)[2][0][0])\n",
        "        mydict = tk.word_index\n",
        "        if d3p==0:\n",
        "            pred3 =  ''\n",
        "            break\n",
        "        word = list(mydict.keys())[list(mydict.values()).index(d3p)]\n",
        "\n",
        "        d3 = [0 for i in range(20)]\n",
        "        d3 = np.array(d3)\n",
        "        d3[0] = tk.word_index[word]\n",
        "        d3 = embedding_matrix[[d3]]\n",
        "        d3 = d3.reshape(20, 300)\n",
        "        inn = []\n",
        "        inn.append([emb_vec_qa, d1, d2, d3])\n",
        "        inn = np.array(inn)\n",
        "        inn = inn.reshape(1, 4, 20, 300)\n",
        "        out = []\n",
        "        c+=1\n",
        "        if word == 'eee' or c > count:\n",
        "            flag = False\n",
        "            pred3 = ' '.join(predict3)\n",
        "        predict3.append(word)\n",
        "\n",
        "    return f\"'{pred1}', '{pred2}', '{pred3}'\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vsXiGZ5Euksy",
        "outputId": "3abf96cd-8fe6-407d-ba4b-88e67ec7c764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dftp = pd.read_csv('Test.csv')\n",
        "dftp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What 'S the main idea of the text ?</td>\n",
              "      <td>The lack of career -- based courses in US high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the summer high season , Finland does nt se...</td>\n",
              "      <td>the sun is out at night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If you want to apply for Chinese Business Inte...</td>\n",
              "      <td>have to get confirmed at least twice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That afternoon , the boy 's clothes were dry b...</td>\n",
              "      <td>nobody made room for him in the water .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which of the following statements is NOT true ?</td>\n",
              "      <td>There are twelve countries in the World Wildli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0                What 'S the main idea of the text ?   \n",
              "1  In the summer high season , Finland does nt se...   \n",
              "2  If you want to apply for Chinese Business Inte...   \n",
              "3  That afternoon , the boy 's clothes were dry b...   \n",
              "4    Which of the following statements is NOT true ?   \n",
              "\n",
              "                                         answer_text  \n",
              "0  The lack of career -- based courses in US high...  \n",
              "1                            the sun is out at night  \n",
              "2               have to get confirmed at least twice  \n",
              "3            nobody made room for him in the water .  \n",
              "4  There are twelve countries in the World Wildli...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4x5WKAyguJSf",
        "colab": {}
      },
      "source": [
        "q = list(dftp['question'])\n",
        "an = list(dftp['answer_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J30c09-38H-q",
        "outputId": "012ab3db-ee39-467b-8a01-9168a0150741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "comb1 = []\n",
        "for i, j in tqdm(zip(q, an)):\n",
        "    comb1.append(i+' ' +j)\n",
        "comb1 = [clean_text(i) for i in tqdm(comb1)]\n",
        "comb1[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13500it [00:00, 1690797.10it/s]\n",
            "100%|██████████| 13500/13500 [00:00<00:00, 48439.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what the main idea of the text the lack of career based courses in us high schools'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YSeR54j4vELg",
        "colab": {},
        "outputId": "7e1058c9-888b-4f8c-ba77-d6cb2fff6194"
      },
      "source": [
        "dis1 = [get_seq(i, 10) for i in tqdm(comb1)]\n",
        "dis1[3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/13500 [00:00<?, ?it/s]/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  after removing the cwd from sys.path.\n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  if __name__ == '__main__':\n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  \n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:97: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "100%|██████████| 13500/13500 [1:15:32<00:00,  3.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'were the man could he wanted his man could he', 'the woman did n t the woman did n t', 'their knew were too was too was too was too'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcpnQmFGuvi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_new = pd.read_csv('Results.csv')\n",
        "df_new['distractor'] = dis1\n",
        "df_new.to_csv('Results.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFiWzh06uvi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obteYNiwuvjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qqZCI81uvjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = list(df['distractor'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tYROx1duvjK",
        "colab_type": "code",
        "colab": {},
        "outputId": "3d6ffbaf-6afd-43c3-ff0d-17ac2f93614d"
      },
      "source": [
        "str(dist[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['idioms are the most important part in a language', 'nonnative speakers should learn more idioms', 'there are no ways to master idioms']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLGecAwpuvjN",
        "colab_type": "code",
        "colab": {},
        "outputId": "197f8318-b2ee-4576-b5ea-02ed12783f3c"
      },
      "source": [
        "l[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'outside the room at 3:00 p. m.', 'in the dining - room at 6:00 p. m.', 'in the dining - room from 7:30 a. m. to 9:15 p. m.'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKya760quvjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5fubUFtkK1dP",
        "outputId": "db3a0296-535f-4696-ade9-0165aa598c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "get_seq('One part of the homeless population is difficult to estimate . The reason might well be some homeless children are deserted by their families', 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the homeless children in the homeless children in the homeless children in',\n",
              " 'the people will be important in two men have two men have',\n",
              " 'the children can be too much is too much is too much']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IKIDFCzIMpaN",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}